### Datasets

Corpus has been prepared by [the same way as in Berturk.](https://github.com/stefan-it/turkish-bert/issues/28)

- [Latest wikipedia dump](https://dumps.wikimedia.org/trwiki/latest/trwiki-latest-pages-articles.xml.bz2)
  - I could not find the dump of latest dump in 2 February 2020 which has been used for BERTurk pre-training 
- Kemal Oflazer's corpus
  - Private
  - Contact with [Mr Oflazer](https://www.andrew.cmu.edu/user/ko/) to get corpus.  
- [OSCAR](https://oscar-corpus.com/post/oscar-2019/)
  - Public
  - Deduplicated version has been used.
- [OPUS](https://opus.nlpl.eu)
   - Public
   - Various datasets:   
     - [Bible Uedin](https://opus.nlpl.eu/bible-uedin.php)
     - [GNOME](https://opus.nlpl.eu/GNOME.php)
     - JW300
     - [OpenSubtitles](https://opus.nlpl.eu/OpenSubtitles.php)
     - [OPUS All](https://opus.nlpl.eu/opus-100.php) (?)
        - Not sure whether this is the one that used in BERTurk pre-training
     - [QED](https://opus.nlpl.eu/QED.php) 
     - [SETIMES](https://opus.nlpl.eu/SETIMES.php)
     - [Tanzil](https://opus.nlpl.eu/Tanzil.php)
     - [Tatoeba](https://opus.nlpl.eu/Tatoeba.php)
     - [TED2013](https://opus.nlpl.eu/TED2013.php)
     - [Wikipedia](https://opus.nlpl.eu/Wikipedia.php)


### Changelog

- 03.11.2021: 
    - Added datasets used
    - Repo initialized
